{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "sys.path.insert(1, '../../reinforcement_learning/code')\n",
    "from env.gridworld_env import GridWorldEnv\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3 \t 8.8 \t 4.4 \t 5.3 \t 1.5 \t \n",
      "\n",
      "1.5 \t 3.0 \t 2.3 \t 1.9 \t 0.5 \t \n",
      "\n",
      "0.1 \t 0.7 \t 0.7 \t 0.4 \t -0.4 \t \n",
      "\n",
      "-1.0 \t -0.4 \t -0.4 \t -0.6 \t -1.2 \t \n",
      "\n",
      "-1.9 \t -1.3 \t -1.2 \t -1.4 \t -2.0 \t \n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_width = 5\n",
    "grid_height = 5\n",
    "env = GridWorldEnv(grid_width, grid_height)\n",
    "action_probability = 0.25\n",
    "discount_factor = 0.9\n",
    "\n",
    "value = np.zeros((grid_width, grid_height))\n",
    "while True:\n",
    "    new_value = np.zeros_like(value)\n",
    "    for i in range(grid_height):\n",
    "        for j in range(grid_width):\n",
    "            for action in env.action_space:\n",
    "                (ni, nj), reward = env.step(state=[i, j], action=action)\n",
    "                new_value[i, j] += action_probability * (reward + discount_factor * value[ni, nj])\n",
    "    \n",
    "    # continue until it reaches tability\n",
    "    diff = np.sum(np.abs(value - new_value))\n",
    "    if diff < 1e-4:\n",
    "        for r in value:\n",
    "            for val in r:\n",
    "                print(\"%.1f \\t\" % round(val, 1), end=\" \")\n",
    "            print('\\n')\n",
    "        break\n",
    "    value = new_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.0 \t 24.4 \t 22.0 \t 19.4 \t 17.5 \t \n",
      "\n",
      "19.8 \t 22.0 \t 19.8 \t 17.8 \t 16.0 \t \n",
      "\n",
      "17.8 \t 19.8 \t 17.8 \t 16.0 \t 14.4 \t \n",
      "\n",
      "16.0 \t 17.8 \t 16.0 \t 14.4 \t 13.0 \t \n",
      "\n",
      "14.4 \t 16.0 \t 14.4 \t 13.0 \t 11.7 \t \n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_width = 5\n",
    "grid_height = 5\n",
    "env = GridWorldEnv(grid_width, grid_height)\n",
    "action_probability = 0.25\n",
    "discount_factor = 0.9\n",
    "\n",
    "value = np.zeros((grid_width, grid_height))\n",
    "while True:\n",
    "    new_value = np.zeros_like(value)\n",
    "    for i in range(grid_height):\n",
    "        for j in range(grid_width):\n",
    "            action_values = []\n",
    "            for action in env.action_space:\n",
    "                (ni, nj), reward = env.step(state=[i, j], action=action)\n",
    "                action_values.append(reward + discount_factor * value[ni, nj])\n",
    "            new_value[i][j] = np.max(action_values)\n",
    "    # continue until it reaches tability\n",
    "    diff = np.sum(np.abs(value - new_value))\n",
    "    if diff < 1e-4:\n",
    "        for r in value:\n",
    "            for val in r:\n",
    "                print(\"%.1f \\t\" % round(val, 1), end=\" \")\n",
    "            print('\\n')\n",
    "        break\n",
    "    value = new_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
